TestROCRpred <- prediction(Log_model.predicted1, test$Churn)
TestROCRperf <- performance(TestROCRpred, 'tpr','fpr')
plot(ROCRperf,colorize = TRUE, text.adj = c(-0.2,1.7),main="AUC Curve of LR MODEL ON TESTING DATASET",xlab="False Positive Rate",ylab="True Positive Rate")
# kS
KS = max(ROCRperf@y.values[[1]]-ROCRperf@x.values[[1]]) # The Maximum the Better
# kS
KS = max(TestROCRperf@y.values[[1]]-TestROCRperf@x.values[[1]]) # The Maximum the Better
print(KS)
auc = performance(TestROCRpred,"auc");
plot(TestROCRperf,colorize = TRUE, text.adj = c(-0.2,1.7),main="AUC Curve of LR MODEL ON TESTING DATASET",xlab="False Positive Rate",ylab="True Positive Rate")
print(TestKS)
# kS
TestKS = max(TestROCRperf@y.values[[1]]-TestROCRperf@x.values[[1]]) # The Maximum the Better
print(TestKS)
Testauc = as.numeric(auc@y.values)
print(auc)
Testauc = performance(TestROCRpred,"auc");
Testauc = as.numeric(auc@y.values)
print(auc)
print(Testauc)
Testgini = ineq(Log_model.predicted1, type="Gini")
print(Testgini)
# KNN
# KNN
library(knn)
# KNN
library(class)
knnmodel <- knn(train,test,train$Churn,k=5)
summary(knnmodel)
table(test$Churn,knnmodel)
install.packages("sjPlot")
library(sjPlot)
sjc.elbow(churn)
help("Deprecated")
sjc.elbow(churn[-1])
sjc.elbow(churn[,-1])
sjc.elbow(churn)
sjplot::sjc.elbow(churn)
sjPlot::sjc.elbow(churn)
sqrt(3333)
knn(train,test,train$Churn,k=57)
table(test$Churn,knn(train,test,train$Churn,k=57))
table(test$Churn,knnmodel)
x <- table(test$Churn,knnmodel)
round(sum(diag(x))/sum(x),2)
y <- table(test$Churn,knn(train,test,train$Churn,k=57))
round(sum(diag(y))/sum(y),2)
table(test$Churn,knnmodel)
# Accuracy
accuracy <- round(sum(diag(knntable))/sum(knntable),2)
# Confusion Matrix
knntable <- table(test$Churn,knnmodel)
# Accuracy
accuracy <- round(sum(diag(knntable))/sum(knntable),2)
print(knntable)
# Accuracy
knnaccuracy <- round(sum(diag(knntable))/sum(knntable),2)
print(knnaccuracy)
# 90 %
# Sensitivity
sensitivity <- round(55/(55+10),2)
print(sensitivity)
# 85 %
# Specificity
specificity <-round(845/(845 + 90),2)
print(specificity)
knnmodel <- knn(train,test,train$Churn,k=31)
summary(knnmodel)
x<- table(test$Churn,knnmodel)
x
# Accuracy
knnaccuracy <- round(sum(diag(knntable))/sum(knntable),2)
print(knnaccuracy)
# Accuracy
knnaccuracy <- round(sum(diag(x))/sum(x),2)
print(knnaccuracy)
knnmodel <- knn(train,test,train$Churn,k=5)
summary(knnmodel)
# Confusion Matrix
knntable <- table(test$Churn,knnmodel)
# Accuracy
knnaccuracy <- round(sum(diag(knntable))/sum(knntable),2)
print(knnaccuracy)
# 90 %
# Sensitivity
sensitivity <- round(55/(55+10),2)
# Confusion Matrix
knntable <- table(test$Churn,knnmodel)
print(knntable)
# Accuracy
knnaccuracy <- round(sum(diag(knntable))/sum(knntable),2)
print(knnaccuracy)
# 90 %
# Sensitivity
sensitivity <- round(55/(55+10),2)
print(sensitivity)
table(train$Churn,knnmodel)
sqrt(3333)
# Naive Bayes
library(e1071)
naiveBayes(Churn~.,data = churn)
naiveBayes(Churn~.,data = test)
NBModel <- naiveBayes(Churn~.,data = test)
summary(NBModel)
print(NBModel)
NBModel <- naiveBayes(Churn~.,data = train)
print(NBModel)
predict(NBModel,type = "raw",newdata = test)
plot(Churn,predict(NBModel,type = "raw",newdata = test))
plot(test$Churn,predict(NBModel,type = "raw",newdata = test))
plot(test$Churn,predict(NBModel,type = "raw",newdata = test)[,2])
plot(test$Churn,predict(NBModel,type = "raw",newdata = test)[,1])
plot(test$Churn,predict(NBModel,type = "raw",newdata = test)[,2])
plot(test$Churn,predict(NBModel,newdata = test)[,2])
plot(test$Churn,predict(NBModel,newdata = test))
plot(test$Churn,predict(NBModel,newdata = test))
plot(test$Churn,predict(NBModel,type = "raw",newdata = test))
plot(test$Churn,predict(NBModel,type = "raw",newdata = test)[,2])
NBPredict <- predict(NBModel,type = "raw",newdata = test)
plot(test$Churn,NBPredict)
plot(test$Churn,NBPredict[,2])
# Confusion Matrix
NaiveBayes <- ifelse(NBPredict <0.25,0,1)
NBTable <- table(test$Churn,NaiveBayes)
length(NBPredict)
View(NBPredict)
length(NaiveBayes)
length(NBPredict)
NBPredict <- predict(NBModel,newdata = test)
View(NBPredict)
NBPredict <- predict(NBModel,newdata = test)
#plot(test$Churn,NBPredict[,2])
# Confusion Matrix
# NaiveBayes <- ifelse(NBPredict <0.25,0,1)
NBTable <- table(test$Churn,NBPredict)
print(NBTable)
# Accuracy
NBaccuracy <- round(sum(diag(NBtable))/sum(NBtable),2)
# Accuracy
NBaccuracy <- round(sum(diag(NBTable))/sum(NBTable),2)
print(NBaccuracy)
# 85 %
# Sensitivity
sensitivity <- round(28/(28+29),2)
print(sensitivity)
# 49 %
# Specificity
NBspecificity <-round(826/(826 + 117),2)
print(NBspecificity)
# Confusion Matrix
NBTrainTable <- table(train$Churn,NBPredictTrain)
NBPredictTrain <- predict(NBModel,newdata = train)
# Confusion Matrix
NBTrainTable <- table(train$Churn,NBPredictTrain)
print(NBTrainTable)
# Accuracy
NBTrainaccuracy <- round(sum(diag(NBTrainTable))/sum(NBTrainTable),2)
print(NBTrainaccuracy)
# 86 %
# Sensitivity
NBTrainsensitivity <- round(57/(57+38),2)
print(NBTrainsensitivity)
# 60 %
# Specificity
NBTrainspecificity <-round(1957/(1957 + 281),2)
print(NBTrainspecificity)
# Let's see how the Naive Bayes Model performs on the Test Data set
NBTestPredict <- predict(NBModel,newdata = test)
#plot(test$Churn,NBPredict[,2])
# Confusion Matrix
# NaiveBayes <- ifelse(NBPredict <0.25,0,1)
NBTestTable <- table(test$Churn,NBTestPredict)
print(NBTestTable)
# Accuracy
NBTestaccuracy <- round(sum(diag(NBTestTable))/sum(NBTestTable),2)
print(NBTestaccuracy)
# 85 %
# Sensitivity
NBTestsensitivity <- round(28/(28+29),2)
print(NBTestsensitivity)
# 49 %
# Specificity
NBTestspecificity <-round(826/(826 + 117),2)
print(NBTestspecificity)
rm(list = ls())
## Importing the Dataset
setwd("D:/Great Lakes/Projects/Predictive Modeling")
getwd()
library(openxlsx)
churn <- read.xlsx("Cellphone.xlsx",2,startRow = 1,colNames = TRUE)
##Understanding the data
### Structure of Data
str(churn)
# we can see that all the Variables are taken as numerical Variable only
# and we know that variables like Churn,Contract Renewal,Data Plan and Customer service calls are Categorical Variable. so need to convert them to categorical variable.
# Let's Convert the class of the Numeric Variable which are supposed to be Categorical Variable to Factor
churn$Churn <- as.factor(churn$Churn)
churn$ContractRenewal <- as.factor(churn$ContractRenewal)
churn$DataPlan <- as.factor(churn$DataPlan)
churn$CustServCalls <- as.factor(churn$CustServCalls)
# Now lets look at the Structure of our Dataset
str(churn)
summary(churn$Churn)
483/(2850+483)
# ContractRenewal - There are 323(10%) customers who haven't renewed thier Contract and 3010(90%) customers who have renewed thier Contract
# Data Plan - There are 2411(72%) customers who didn't have data Plan and 922(18%) customers who have data plan. It Shows that most of our customers don't use our Data Plans
# Data Usage -The Maximum Data Used by our customers is 5.4 Gb, on an average our customers use 0.8 gb.
# DayMins - On an average 180 Minutes per day is spent on Call by our customers,it reaches upto 3510 Minutes per day.
# Daycalls - On an average around 100 Day Time calls are spoken by our cutomers,it reaches upto 165 Day Calls per day.
# MonthlyCharge - Average Monthly Bill comes around 57 rupees per month and it reaches upto 112 rupees per month.
# Overage Fee - An Overage Fee is an extra amount of money that you have to pay for using more of something than was expected or agreed.The Average Overage Fee in last 12 Months is 10rupees and it reaches upto 19 rupees.
# RoamMins - Average number of Roaming Minutes is 10 minutes and it reaches a maximum of 20 Minutes.
## Checking NA Values/ Missing Values
# sum(is.na(churn))
colSums(is.na(churn))
# Exploratory Data Analysis
##  Univariate Analysis
## Outlier Detection
library(ggplot2)
#par(mfrow = c(2,2))
# dev.off()
ggplot(churn,aes(x="",churn$AccountWeeks))+
geom_boxplot(fill='green', color="black",outlier.colour="black", outlier.shape=16,outlier.size=2, notch=FALSE)+ labs(x = "AccountWeeks" , y = "") + theme(plot.title = element_text(hjust = 0.5))+ggtitle("Boxplot of AccountWeeks")
ggplot(churn,aes(x="",churn$DataUsage))+
geom_boxplot(fill='blue', color="black",outlier.colour="black", outlier.shape=16,outlier.size=2, notch=FALSE)+ labs(x = "Data Usage" , y = "") + theme(plot.title = element_text(hjust = 0.5))+ggtitle("Boxplot of Data Usage")
ggplot(churn,aes(x="",churn$DayMins))+
geom_boxplot(fill='yellow', color="black",outlier.colour="black", outlier.shape=16,outlier.size=2, notch=FALSE)+ labs(x = "Day Minutes" , y = "") + theme(plot.title = element_text(hjust = 0.5))+ggtitle("Boxplot of Day Minutes")
ggplot(churn,aes(x="",churn$DayCalls))+
geom_boxplot(fill='red', color="black",outlier.colour="black", outlier.shape=16,outlier.size=2, notch=FALSE)+ labs(x = "Day Calls" , y = "") + theme(plot.title = element_text(hjust = 0.5))+ggtitle("Boxplot of Day Calls")
ggplot(churn,aes(x="",churn$MonthlyCharge))+
geom_boxplot(fill='Purple', color="black",outlier.colour="black", outlier.shape=16,outlier.size=2, notch=FALSE)+ labs(x = "Monthly Charge" , y = "") + theme(plot.title = element_text(hjust = 0.5))+ggtitle("Boxplot of Monthly Charge")
ggplot(churn,aes(x="",churn$OverageFee))+
geom_boxplot(fill='Violet', color="black",outlier.colour="black", outlier.shape=16,outlier.size=2, notch=FALSE)+ labs(x = "Overage Fee" , y = "") + theme(plot.title = element_text(hjust = 0.5))+ggtitle("Boxplot of Over Age Fee")
ggplot(churn,aes(x="",churn$RoamMins))+
geom_boxplot(fill='grey', color="black",outlier.colour="black", outlier.shape=16,outlier.size=2, notch=FALSE)+ labs(x = "Roam Minutes" , y = "") + theme(plot.title = element_text(hjust = 0.5))+ggtitle("Boxplot of Roam Minutes")
ggplot(churn,aes(x=Churn))+geom_bar(fill = "#FF9999",colour = "Black")+ggtitle("churn")+theme(plot.title = element_text(hjust = 0.5))+xlab("Customer Churn")
# Churn - There are 2850 (86%) customers who haven't Churned Out and 483(14%) customers who have churned out
ggplot(churn,aes(x=AccountWeeks))+geom_histogram(bins = 50,fill = "Blue",colour = "Black")+ggtitle("AccountWeeks")+theme(plot.title = element_text(hjust = 0.5))+xlab("AccountWeeks")
# Account Weeks - The Number of Hours the customer had active accounts ranges from minimum of 1 week to maximum of 243 weeks.The Average Number of week lies around 101
ggplot(churn,aes(x=ContractRenewal))+geom_bar(fill = "#E69F00",colour = "Black")+ggtitle("Contract Renewal")+theme(plot.title = element_text(hjust = 0.5))+xlab("Contract Renewal")
# ContractRenewal - There are 323(10%) customers who haven't renewed thier Contract and 3010(90%) customers who have renewed thier Contract
ggplot(churn,aes(x=DataPlan))+geom_bar(fill = "#56B4E9",colour = "Black")+ggtitle("Data Plan")+theme(plot.title = element_text(hjust = 0.5))+xlab("Data Plan")
# Data Plan - There are 2411(72%) customers who didn't have data Plan and 922(18%) customers who have data plan. It Shows that most of our customers don't use our Data Plans
ggplot(churn,aes(x=DataUsage))+geom_histogram(bins = 50,fill = "Blue",colour = "Black")+ggtitle("Data Usage")+theme(plot.title = element_text(hjust = 0.5))+xlab("Data Usage")
# Data Usage -The Maximum Data Used by our customers is 5.4 Gb, on an average our customers use 0.8 gb.
ggplot(churn,aes(x = CustServCalls))+ geom_bar(fill = "#009E73",colour = "Black")+ ggtitle("Customer Service Calls") + theme(plot.title = element_text(hjust = 0.5))+xlab("Customer Service Calls")
# Customer Service Calls - A lot of our customers atleast have one Customer service calls
ggplot(churn,aes(x=DayMins))+geom_histogram(bins = 50,fill = "purple",colour = "Black")+ggtitle("Day Minutes")+theme(plot.title = element_text(hjust = 0.5))+xlab("Data Minutes")
# DayMins - On an average 180 Minutes per day is spent on Call by our customers,it reaches upto 3510 Minutes per day.
ggplot(churn,aes(x=DayCalls))+geom_histogram(bins = 50,fill = "violet",colour = "Black")+ggtitle("Day Calls")+theme(plot.title = element_text(hjust = 0.5))+xlab("Day Calls")
# Daycalls - On an average around 100 Day Time calls are spoken by our cutomers,it reaches upto 165 Day Calls per day.
ggplot(churn,aes(x=MonthlyCharge))+geom_histogram(bins = 50,fill = "green",colour = "Black")+ggtitle("Monthly Charge")+theme(plot.title = element_text(hjust = 0.5))+xlab("Monthly Charge")
# MonthlyCharge - Average Monthly Bill comes around 57 rupees per month and it reaches upto 112 rupees per month.
ggplot(churn,aes(x=OverageFee))+geom_histogram(bins = 50,fill = "yellow",colour = "Black")+ggtitle("Overage Fee")+theme(plot.title = element_text(hjust = 0.5))+xlab("Overage Fee")
# Overage Fee - An Overage Fee is an extra amount of money that you have to pay for using more of something than was expected or agreed.The Average Overage Fee in last 12 Months is 10rupees and it reaches upto 19 rupees.
ggplot(churn,aes(x=RoamMins))+geom_histogram(bins = 50,fill = "Red",colour = "Black")+ggtitle("Roaming Minutes")+theme(plot.title = element_text(hjust = 0.5))+xlab("Roaming Minutes")
# Bi-Variate Analysis
ggplot(churn,aes(AccountWeeks,fill = Churn))+geom_bar()+ggtitle("AccountWeeks vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Account Weeks")
# From the Graph, we can clearly see that Lesser the Customer stays higher the chance of Churning Out
ggplot(churn,aes(ContractRenewal,fill = Churn))+geom_bar()+ggtitle("Contract Renewal vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Contract Renewal")
# As expected people who have renewed the contract has less possibility of churning out
ggplot(churn,aes(DataPlan,fill = Churn))+geom_bar()+ggtitle("DataPlan vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("DataPlan")
# As expected people who have renewed the contract has less possibility of churning out
ggplot(churn,aes(DataPlan,fill = Churn))+geom_bar()+ggtitle("DataPlan vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("DataPlan")
ggplot(churn,aes(x=Churn))+geom_bar(fill = "#FF9999",colour = "Black")+ggtitle("churn")+theme(plot.title = element_text(hjust = 0.5))+xlab("Customer Churn")
# Churn - There are 2850 (86%) customers who haven't Churned Out and 483(14%) customers who have churned out
ggplot(churn,aes(x=AccountWeeks))+geom_histogram(bins = 50,fill = "Blue",colour = "Black")+ggtitle("AccountWeeks")+theme(plot.title = element_text(hjust = 0.5))+xlab("AccountWeeks")
ggplot(churn,aes(x=Churn))+geom_bar(fill = "#FF9999",colour = "Black")+ggtitle("churn")+theme(plot.title = element_text(hjust = 0.5))+xlab("Customer Churn")
# Churn - There are 2850 (86%) customers who haven't Churned Out and 483(14%) customers who have churned out
ggplot(churn,aes(x=AccountWeeks))+geom_histogram(bins = 50,fill = "Blue",colour = "Black")+ggtitle("AccountWeeks")+theme(plot.title = element_text(hjust = 0.5))+xlab("AccountWeeks")
# Account Weeks - The Number of Hours the customer had active accounts ranges from minimum of 1 week to maximum of 243 weeks.The Average Number of week lies around 101
ggplot(churn,aes(x=ContractRenewal))+geom_bar(fill = "#E69F00",colour = "Black")+ggtitle("Contract Renewal")+theme(plot.title = element_text(hjust = 0.5))+xlab("Contract Renewal")
# ContractRenewal - There are 323(10%) customers who haven't renewed thier Contract and 3010(90%) customers who have renewed thier Contract
ggplot(churn,aes(x=DataPlan))+geom_bar(fill = "#56B4E9",colour = "Black")+ggtitle("Data Plan")+theme(plot.title = element_text(hjust = 0.5))+xlab("Data Plan")
# Data Plan - There are 2411(72%) customers who didn't have data Plan and 922(18%) customers who have data plan. It Shows that most of our customers don't use our Data Plans
ggplot(churn,aes(x=DataUsage))+geom_histogram(bins = 50,fill = "Blue",colour = "Black")+ggtitle("Data Usage")+theme(plot.title = element_text(hjust = 0.5))+xlab("Data Usage")
# Data Usage -The Maximum Data Used by our customers is 5.4 Gb, on an average our customers use 0.8 gb.
ggplot(churn,aes(x = CustServCalls))+ geom_bar(fill = "#009E73",colour = "Black")+ ggtitle("Customer Service Calls") + theme(plot.title = element_text(hjust = 0.5))+xlab("Customer Service Calls")
# Customer Service Calls - A lot of our customers atleast have one Customer service calls
ggplot(churn,aes(x=DayMins))+geom_histogram(bins = 50,fill = "purple",colour = "Black")+ggtitle("Day Minutes")+theme(plot.title = element_text(hjust = 0.5))+xlab("Data Minutes")
# DayMins - On an average 180 Minutes per day is spent on Call by our customers,it reaches upto 3510 Minutes per day.
ggplot(churn,aes(x=DayCalls))+geom_histogram(bins = 50,fill = "violet",colour = "Black")+ggtitle("Day Calls")+theme(plot.title = element_text(hjust = 0.5))+xlab("Day Calls")
# Daycalls - On an average around 100 Day Time calls are spoken by our cutomers,it reaches upto 165 Day Calls per day.
ggplot(churn,aes(x=MonthlyCharge))+geom_histogram(bins = 50,fill = "green",colour = "Black")+ggtitle("Monthly Charge")+theme(plot.title = element_text(hjust = 0.5))+xlab("Monthly Charge")
# MonthlyCharge - Average Monthly Bill comes around 57 rupees per month and it reaches upto 112 rupees per month.
ggplot(churn,aes(x=OverageFee))+geom_histogram(bins = 50,fill = "yellow",colour = "Black")+ggtitle("Overage Fee")+theme(plot.title = element_text(hjust = 0.5))+xlab("Overage Fee")
# Overage Fee - An Overage Fee is an extra amount of money that you have to pay for using more of something than was expected or agreed.The Average Overage Fee in last 12 Months is 10rupees and it reaches upto 19 rupees.
ggplot(churn,aes(x=RoamMins))+geom_histogram(bins = 50,fill = "Red",colour = "Black")+ggtitle("Roaming Minutes")+theme(plot.title = element_text(hjust = 0.5))+xlab("Roaming Minutes")
# Bi-Variate Analysis
ggplot(churn,aes(AccountWeeks,fill = Churn))+geom_bar()+ggtitle("AccountWeeks vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Account Weeks")
# From the Graph, we can clearly see that Lesser the Customer stays higher the chance of Churning Out
ggplot(churn,aes(ContractRenewal,fill = Churn))+geom_bar()+ggtitle("Contract Renewal vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Contract Renewal")
# As expected people who have renewed the contract has less possibility of churning out
ggplot(churn,aes(DataPlan,fill = Churn))+geom_bar()+ggtitle("DataPlan vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("DataPlan")
# Here,The customer who doesn't have data plan have churned out lot more than the customers who have data plan.
# ggplot(churn,aes(DataUsage,fill = Churn))+geom_bar()+ggtitle("DataUsage vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("DataUsage")
ggplot(churn,aes(CustServCalls,fill = Churn))+geom_bar()+ggtitle("Customer Service Call vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Customer Service Calls")
# Higher the Customer Service Calls made by the Customers Higher the Possibility of churning out
# ggplot(churn,aes(DayMins,fill = Churn))+geom_bar()+ggtitle("Day Minutes vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Day Minutes")
# ggplot(churn,aes(DayCalls,fill = Churn))+geom_bar()+ggtitle("Day Calls vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Day Calls")
ggplot(churn,aes(MonthlyCharge,fill = Churn))+geom_histogram()+ggtitle("Monthly Charge vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Monthly Charge")
library(corrgram)
library(corrplot)
library(car)
corrplot::corrplot(corrgram(churn[,-c(1,3,4,6)]))
cor(churn[,-c(1,3,4,6)])
model <- glm(Churn~.,churn,family = "binomial")
summary(model)
vif(model)
churn1 <- churn[,-c(4,5,9)]
model <- glm(Churn~.,churn,family = "binomial")
summary(model)
churn1 <- churn[,-c(4,5,9)]
model1 <- glm(Churn~.,churn2,family = "binomial")
vif(model1)
model1 <- glm(Churn~.,churn1,family = "binomial")
vif(model1)
# The Vif of all the other variables are around 1,i.e. they are less correlated with each other.
summary(model1)
library(caTools)
set.seed(1234)
churn3 <- churn[,c(1,3,6,7,10)]
split <- sample.split(churn3$Churn, SplitRatio = 0.7)
train <- subset(churn3,split== TRUE)
test <- subset(churn3,split == FALSE)
rm(churn3)
library(caTools)# Used for Spliting the Data
set.seed(1234)
churn2 <- churn[,c(1,3,6,7,10)]
split <- sample.split(churn2$Churn, SplitRatio = 0.7)
train <- subset(churn2,split== TRUE)
test <- subset(churn2,split == FALSE)
LogTrainModel <- glm(Churn~.,train,family = "binomial")
summary(LogTrainModel)
# As expected people who have renewed the contract has less possibility of churning out
ggplot(churn,aes(DataPlan,fill = Churn))+geom_bar()+ggtitle("DataPlan vs Churn")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("DataPlan")
summary(LogTrainModel)
plot(train$Churn,Log_model$fitted.values)
plot(train$Churn,LogTrainmodel$fitted.values)
plot(train$Churn,LogTrainModel$fitted.values)
plot(train$Churn,LogTrainModel$fitted.values)
Log_Prediction_Train <- predict(Log_model,data = "train",type = "response")
Log_Prediction_Train <- predict(LogTrainModel,data = "train",type = "response")
plot(train$Churn,Log_Prediction_Train)
# Confusion Matrix
Log_model.predicted <- ifelse(Log_Prediction_Train<0.3,0,1)
# Confusion Matrix
Log_model.predicted <- ifelse(Log_Prediction_Train<0.3,0,1)
Logmodel <- table(train$Churn,Log_model.predicted)
print(Logmodel)
# Now Let's Check Our Model with other Model Perfomance measures like AUC, Gini,KS
# Rocr
library(ROCR)
ROCRpred <- prediction(Log_model.predicted, train$Churn)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf,colorize = TRUE, text.adj = c(-0.2,1.7),main="AUC Curve of LR MODEL ON TRAINING DATASET",xlab="False Positive Rate",ylab="True Positive Rate")
auc = performance(ROCRpred,"auc");
auc = as.numeric(auc@y.values)
print(auc)
library(ineq)
gini = ineq(Log_model.predicted, type="Gini")
print(gini)
Log_Prediction_Test <- predict(Log_model,test,type = "response")
Log_Prediction_Test <- predict(LogTrainModel,test,type = "response")
# Confusion Matrix
Log_model.predicted1 <- ifelse(Log_Prediction_Test <0.3,0,1)
Logmodel1 <- table(test$Churn,Log_model.predicted1)
print(Logmodel1)
# Accuracy
Test_accuracy <- round(sum(diag(Logmodel1))/sum(Logmodel1),2)
print(Test_accuracy)
# 84 %
# Sensitivity
sensitivity <- round(60/(60+71),2)
print(sensitivity)
# 46 %
# Specificity
specificity <-round(784/(784 + 85),2)
print(specificity)
TestROCRpred <- prediction(Log_model.predicted1, test$Churn)
TestROCRperf <- performance(TestROCRpred, 'tpr','fpr')
plot(TestROCRperf,colorize = TRUE, text.adj = c(-0.2,1.7),main="AUC Curve of LR MODEL ON TESTING DATASET",xlab="False Positive Rate",ylab="True Positive Rate")
plot(TestROCRperf,colorize = TRUE, text.adj = c(-0.2,1.7),main="AUC Curve of LR MODEL ON TESTING DATASET",xlab="False Positive Rate",ylab="True Positive Rate")
Testauc = performance(TestROCRpred,"auc");
Testauc = as.numeric(auc@y.values)
print(Testauc)
Testauc = as.numeric(auc@y.values)
Testauc = as.numeric(auc@y.values)
TestROCRpred <- prediction(Log_model.predicted1, test$Churn)
TestROCRperf <- performance(TestROCRpred, 'tpr','fpr')
plot(TestROCRperf,colorize = TRUE, text.adj = c(-0.2,1.7),main="AUC Curve of LR MODEL ON TESTING DATASET",xlab="False Positive Rate",ylab="True Positive Rate")
Testauc = performance(TestROCRpred,"auc");
Testauc = as.numeric(auc@y.values)
Testauc@y.values
Testauc = as.numeric(Testauc@y.values)
print(Testauc)
library(ineq)
# Gini on Test dataset
Testgini = ineq(Log_model.predicted1, type="Gini")
print(Testgini)
# kS
TestKS = max(TestROCRperf@y.values[[1]]-TestROCRperf@x.values[[1]]) # The Maximum the Better
print(TestKS)
# KNN
library(class)
knnmodel <- knn(train,test,train$Churn,k=5)
summary(knnmodel)
sqrt(len(3333))
sqrt(length(train))
length(train)
sqrt(2333)
summary(knn(train,test,train$Churn,k=48))
table(test$Churn,summary(knn(train,test,train$Churn,k=48)))
summary(knnmodel)
table(test$Churn,knn(train,test,train$Churn,k=48))
table(test$Churn,knn(train,test,train$Churn,k=45))
table
table(train$Churn,knn(train,test,train$Churn,k=5))
length(knn(train,test,train$Churn,k=5))
table(test$Churn,knn(train,test,train$Churn,k=5))
table(test$Churn,knn(train,test,train$Churn,k=1))
table(test$Churn)
table(test$Churn,knn(train,test,train$Churn,k=15))
table(test$Churn,knn(train,test,train$Churn,k=20))
table(test$Churn,knn(train,test,train$Churn,k=25))
table(test$Churn,knn(train,test,train$Churn,k=30))
table(test$Churn,knn(train,test,train$Churn,k=35))
table(test$Churn,knn(train,test,train$Churn,k=40))
table(test$Churn,knn(train,test,train$Churn,k=45))
# KNN
library(class)
knnmodel <- knn(train,test,train$Churn,k=5)
summary(knnmodel)
# Now, Let's Check how well it have performed by using Confusion Matrix
# Confusion Matrix
knntable <- table(test$Churn,knnmodel)
print(knntable)
# Accuracy
knnaccuracy <- round(sum(diag(knntable))/sum(knntable),2)
print(knnaccuracy)
# Sensitivity
sensitivity <- round(55/(55+10),2)
print(sensitivity)
# Specificity
specificity <-round(845/(845 + 90),2)
print(specificity)
# Naive Bayes
# The Naive Bayes is a classification algorithm that is suitable for binary and multiclass classification.
# Generally,NaÃ¯ve Bayes performs well in cases of categorical input variables compared to numerical variables.
# So a version of Naive Bayes algorithm has been created where the predicted variable do not have to be descrete they can be continuous also.
# However,it is useful for making predictions and forecasting data based on historical results.
# so therefore we can use Naive Bayes Algorithm for this use case
# Let's Build the model and see its performance on the Test data.
library(e1071)
NBModel <- naiveBayes(Churn~.,data = train)
print(NBModel)
NBPredictTrain <- predict(NBModel,newdata = train)
# Confusion Matrix
NBTrainTable <- table(train$Churn,NBPredictTrain)
print(NBTrainTable)
# Accuracy
NBTrainaccuracy <- round(sum(diag(NBTrainTable))/sum(NBTrainTable),2)
print(NBTrainaccuracy)
# Sensitivity
NBTrainsensitivity <- round(57/(57+38),2)
print(NBTrainsensitivity)
# Specificity
NBTrainspecificity <-round(1957/(1957 + 281),2)
print(NBTrainspecificity)
# Let's Look, how the Naive Bayes Model performs on the Test Data set
NBTestPredict <- predict(NBModel,newdata = test)
# Confusion Matrix
# NaiveBayes <- ifelse(NBPredict <0.25,0,1)
NBTestTable <- table(test$Churn,NBTestPredict)
print(NBTestTable)
# Accuracy
NBTestaccuracy <- round(sum(diag(NBTestTable))/sum(NBTestTable),2)
print(NBTestaccuracy)
# Sensitivity
NBTestsensitivity <- round(28/(28+29),2)
print(NBTestsensitivity)
# Specificity
NBTestspecificity <-round(826/(826 + 117),2)
print(NBTestspecificity)
ACCURACY
accuracy
# Accuracy
accuracy <- round(sum(diag(Logmodel))/sum(Logmodel),2)
print(accuracy)
# Sensitivity
sensitivity <- round(143/(143+170),2)
print(sensitivity)
# Specificity
specificity <-round(1825/(1825 + 195),2)
print(specificity)
print(auc)
print(Test_accuracy)
print(Testauc)
print(knnaccuracy)
print(sensitivity)
print(specificity)
print(sensitivity)
# Sensitivity
sensitivity <- round(55/(55+10),2)
print(sensitivity)
print(NBTrainaccuracy)
print(NBTrainsensitivity)
print(NBTrainspecificity)
print(NBTestTable)
print(NBTestaccuracy)
print(NBTestsensitivity)
print(NBTestspecificity)
