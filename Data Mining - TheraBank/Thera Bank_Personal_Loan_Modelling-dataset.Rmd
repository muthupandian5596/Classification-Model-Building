---
title: "Thera Bank - Loan Purchase Modeling"
author: "Muthu Pandian G"
date: "October 11, 2019"
output: word_document
---
# Thera Bank - Loan Purchase Modeling
## OBJECTIVE OF THE PROJECT:
  This case is about a bank (Thera Bank) which has a growing customer base. Majority of these customers are liability customers (depositors) with varying size of deposits.
  The number of customers who are also borrowers (asset customers) is quite small, and the bank is interested in expanding this base rapidly to bring in more loan business and in the process, earn more through the interest on loans.
  In particular, the management wants to explore ways of converting its liability customers to personal loan customers (while retaining them as depositors). 
  A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise campaigns with better target marketing to increase the success ratio with a minimal budget.
  The department wants to build a model that will help them identify the potential customers who have a higher probability of purchasing the loan. This will increase the success ratio while at the same time reduce the cost of the campaign. The dataset has data on 5000 customers.
  The data include customer demographic information (age, income, etc.), the customer's relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). 
  Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.
  You are brought in as a consultant and your job is to build the best model which can classify the right customers who have a higher probability of purchasing the loan. 
  You are expected to do the following:
  .	EDA of the data available. Showcase the results using appropriate graphs
  .	Apply appropriate clustering on the data and interpret the output
  .	Build appropriate models on both the test and train data (CART & Random Forest). Interpret all the model outputs and do the necessary modifications wherever eligible (such as pruning)    .	Check the performance of all the models that you have built (test and train). Use all the model performance measures you have learned so far. Share your remarks on which model performs the best.
  
## Importing the Dataset
```{r}
setwd("D:/Great Lakes/Projects/DATA MINING")
getwd()
library(openxlsx)
thera <- read.xlsx("Thera Bank_Personal_Loan_Modelling-dataset-1.xlsx",sheet = "Bank_Personal_Loan_Modelling",startRow = 1)
```
##Understanding the data
### Structure of Data
```{r}
str(thera)
```
The dataset has data on 5000 customers.
  The data include customer demographic information (age, income, etc.), the customer's relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan).
  Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.
## Data Description

### Summary
```{r}
summary(thera)
```
From the summary we can see that the age of our customers ranges from 23 years to 67 years.
It's also seen that the Experience has negative values in it. As it doesn't make any sense,we need to convert them to 0
```{r}
thera$`Experience.(in.years)` <-replace(thera$`Experience.(in.years)`,thera$`Experience.(in.years)`< 0,0)
summary(thera$`Experience.(in.years)`)
```
## Checking NA Values/ Missing Values
  we can also see that there are 18 NA's Present in the Family Variable.Let's cross check them with is.na command.
```{r}
sum(is.na(thera))
```
  We can replace the NA's with  0 as the Na's represents only 0.36% of total dataset and it won't affect much.
```{r}
thera[is.na(thera)]<- 0
```
## Converting numeric variables into factor Variables.
  Here Education,Personal.Loan,Securities.Account,CD.Account,Online,CreditCard can be converted into factor variables.
```{r}
thera$Education <- as.factor(thera$Education)
thera$Family.members <- as.factor(thera$Family.members)
thera$Personal.Loan <- as.factor(thera$Personal.Loan)
thera$Securities.Account <- as.factor(thera$Securities.Account)
thera$CD.Account <- as.factor(thera$CD.Account)
thera$Online <- as.factor(thera$Online)
thera$CreditCard <- as.factor(thera$CreditCard)
str(thera)
```
# Exploratory Data Analysis 
## Univariate Analysis
### Frequency Distribution of each Independent numerical Variable
```{r}
library(ggplot2)
ggplot(data=thera,aes(x=`Income.(in.K/month)`))+geom_histogram(bins = 50,fill = "Blue",colour = "Black")+ggtitle("Income")+theme(plot.title = element_text(hjust = 0.5))+xlab("Income(in k/Month)")
```
The Income range of our customers varies from lower income people to higher income people with many customers income lies near 45-50 k/month
```{r}
ggplot(data=thera,aes(x=Family.members))+geom_bar(fill = "#FF9999",colour = "Black")+ggtitle("Family Members")+theme(plot.title = element_text(hjust = 0.5))+xlab("Family Members")
```
Most Of our customers has a family size of 1 or 2 members but one mostly
```{r}
ggplot(data=thera,aes(x=CCAvg))+geom_histogram(bins = 20,fill = "Red",colour = "Black")+ggtitle("Credit Card Average")+theme(plot.title = element_text(hjust = 0.5))+xlab("Credit Card Average")
```
Mostly Our customers Avg. spending on credit cards per month lies around 1 to 2
```{r}
ggplot(data=thera,aes(x=Mortgage))+geom_histogram(bins = 10,fill = "Red",colour = "Black")+ggtitle("Mortgage Distribution")+theme(plot.title = element_text(hjust = 0.5))+xlab("Mortgage")
```
Around 70% of our customers haven't got mortgage from our bank yet
```{r}
ggplot(data=thera,aes(x=Personal.Loan))+geom_bar(fill = "#E69F00",colour = "Black")+ggtitle("PersonalLoan")+theme(plot.title = element_text(hjust = 0.5))+xlab("Personal Loan")
```
9%(480) of customers only have accepted the personal loan offered in the last campaign
```{r}
ggplot(data=thera,aes(x=Securities.Account))+geom_bar(fill = "purple",colour = "Black")+ggtitle("Securities Account")+theme(plot.title = element_text(hjust = 0.5))+xlab("Securities Account")
```
10 %(522) of customers only have securities account with thera Bank 
```{r}
ggplot(data=thera,aes(x=CD.Account))+geom_bar(fill = "palegreen4",colour = "Black")+ggtitle("CD Account")+theme(plot.title = element_text(hjust = 0.5))+xlab("CD Account")
```
6 % (302) of customers only have Certificate of Deposit (CD)account with thera Bank 
```{r}
ggplot(data=thera,aes(x=Online))+geom_bar(fill = "yellow",colour = "Black")+ggtitle("Online")+theme(plot.title = element_text(hjust = 0.5))+xlab("Online")
```
nearly 60% (2969) customers use internet banking facilities provided by our thera Bank
```{r}
ggplot(data=thera,aes(x=CreditCard))+geom_bar(fill = "#D55E00",colour = "Black")+ggtitle("CreditCard")+theme(plot.title = element_text(hjust = 0.5))+xlab("CreditCard")
```
29% of the customer use a credit card issued by thera bank

## Bi Variable and Multi Variable analysis
```{r}
ggplot(thera,aes(CreditCard,fill = Personal.Loan))+geom_bar()+ggtitle("Credit Card vs Personal Loan")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Credit Card")
```
  From the plot its clear that the customers who doesn't have credit card had personal loan when compared to customers who have credit card with the bank.
```{r}
ggplot(thera,aes(Online,fill = Personal.Loan))+geom_bar()+ggtitle("Online Account vs Personal Loan")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Online Account")
```
  From the above graph we can clearly see that the customers who has Online Account had personal loan when compared to customers who doesn't have Online account.
```{r}
ggplot(thera,aes(CD.Account,fill = Personal.Loan))+geom_bar()+ggtitle("CD Account vs Personal Loan")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("CD Account")
```
  Here we can see that the customers who didn't interested in depositing has acquired personal loan than the customers who have a Certificate of Deposit Account with the Bank.
```{r}
ggplot(thera,aes(Securities.Account,fill = Personal.Loan))+geom_bar()+ggtitle("Security Account vs Personal Loan")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Security Account")
```
  Similarly,here the customer who doesn't have Security Account with the bank are more likely to accept the personal Loan than the customers with security account
```{r}
ggplot(thera,aes(Education,fill = Personal.Loan))+geom_bar()+ggtitle("Education vs Personal Loan")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Education")
```
  From the above plot we can see that higher the education more the requirement of money hence the graduate and advanced Professionals has acquired Personal Loan than the Undergrad and Graduate
```{r}
ggplot(thera,aes(Family.members,fill = Personal.Loan))+geom_bar()+ggtitle("Family Members vs Personal Loan")+ theme(plot.title = element_text(hjust = 0.5))+ xlab("Family Members")
```
  As per our data , we can see that there is no significant relationship between Family Members and Personal Loan.
  Since Zip Code and ID doesn't have any impact on Personal.Loan we can remove Zip Code from our dataset
```{r}
cor(as.numeric(thera$Personal.Loan),thera$ZIP.Code)
thera <- thera[,-c(1,5)]
```
## Clustering 
Reason For Choosing k-means Clustering Over Hierarchial Clustering
Hierarchical clustering can't handle big data well but K Means clustering can. 
This is because the time complexity of K Means is linear i.e. O(n) while that of hierarchical clustering is quadratic i.e. O(n2).
So we choose K-means Clustering Over Hierarchial CLustering.
## K-Means Clustering 
For clustering we need numerical variables so we remove the categorical variables
```{r}
thera_no_cat <- thera[,-c(4,6,8,9,10,11,12)]
str(thera_no_cat)
```
### Step1 : we need to give the number of centers (k-value)
Let's figure out the optimum k-value by using elbow method
### Required R packages
We'll use the following R packages:
  factoextra to determine the optimal number clusters for a given clustering methods and for data visualization.
  NbClust for computing about 30 methods at once, in order to find the optimal number of clusters.
```{r}
library(factoextra)
library(NbClust)
```
### Scaling the Data 
we scale all the columns to mean zero and unit standard deviation so that we eliminate the dominance of one variable on the other 
```{r}
set.seed(123)
# we use set.seed for the purpose of reproducibility
therascale <- scale(thera_no_cat)
head(therascale)
```
Let's check whether we have mean zero and unit SD
```{r}
apply(therascale,2,mean)
apply(therascale,2,sd)
```
Let's figure out the optimum k-value by using elbow method
```{r}
fviz_nbclust(therascale,kmeans,method = "wss")+geom_vline(xintercept = 4,linetype = 2)
```
By Using Elbow Method on the above plot, we can say that the optimal number of clusters for our datatset is 4.
```{r}
# Let's cross check it by using NbClust Function
NbClust(thera_no_cat,min.nc = 2,max.nc = 5,method = "kmeans")
#*** : The Hubert index is a graphical method of determining the number of clusters.
#In the plot of Hubert index, we seek a significant knee that corresponds to a 
#significant increase of the value of the measure i.e the significant peak in Hubert
#index second differences plot. 
#*** : The D index is a graphical method of determining the number of clusters. 
#In the plot of D index, we seek a significant knee (the significant peak in Dindex
#                                                    second differences plot) that corresponds to a significant increase of the value of
#the measure. 
#* Among all indices:                                                
#  * 8 proposed 2 as the best number of clusters 
#* 2 proposed 3 as the best number of clusters 
#* 12 proposed 4 as the best number of clusters 
#* 2 proposed 5 as the best number of clusters 
#* According to the majority rule, the best number of clusters is  4 
#***** Conclusion *****
```
Let's do K-means clustering with k-value as 4
```{r}
set.seed(123)
kmeans.cluster=kmeans(therascale,4,nstart = 10)
print(kmeans.cluster)
```
As shown above, K-means has formed 4 clusters of sizes 900,327,2581,1192.
K-means cluster also gives  Within cluster sum of squares by cluster (Variance) 
i.e., how similar are the members within the same group.In this case we have 57.8% similarity within the groups.
let's add the cluster column in our original dataset 
```{r}
thera_no_cat$cluster <- kmeans.cluster$cluster
head(thera_no_cat,10)
clusterProfile <- aggregate(thera_no_cat[,-6],list(thera_no_cat$cluster),FUN = "mean")
clusterProfile
```
Here we have 4 groups ,
The 1st segment of customers are "older customers" as their average age group is 55 years.
The 2nd segment of customers are  " comparably younger customers of all the groups as their average age group is 35 years.
The 3rd and 4th segment of customers are  "Middle Aged customers" as their average age group is 35 years.
Here we have 57.8% similarity within the groups(as we have scaled the data).
Let's plot and see the 4 clusters
```{r}
library(cluster)
clusplot(thera_no_cat,kmeans.cluster$cluster,color = TRUE,shade = TRUE,lines = 1)
```
### CART MODEL
Now Let's a Build Model 
Since Our Dependent Variable is categorical (0,1) we use Cart model
```{r}
library(rpart)# TO Build CART Decision Trees
library(rpart.plot)# To Visualise the Decision Trees
library(caTools) # To use sample.split function
```
let's split the data into train and test data so we can test our model performances later on.
```{r}
split <- sample.split(thera$Personal.Loan, SplitRatio = 0.7)
train <- subset(thera,split== TRUE)
test <- subset(thera,split == FALSE)
```
Now, Let's Build a Complex tree model with no cp value and see how the model looks like.
```{r}
cart_tree <- rpart(formula = train$Personal.Loan~.,data = train,method = "class",cp=0)
print(cart_tree)
```
let's Visualize the tree so that we can have clear interpretation
```{r}
rpart.plot(cart_tree)
```
Our Tree has 1root node,16 branches(decision nodes) and 17 leaf nodes.
Here the tree splits the root node based on the income variable as it has the least gini impurity at income level of 115 k/month.
Likewise it has splitted further 13 branches 
The root node has predicted 0 (Customer didn't accept the personal loan offered by the bank) with a probability of 90 %
As per Our Model when the income is greater than 115 k/month and the customer has education level of either graduate or Advanced/Professionals then they are more likely to accept our loan offer.
Likewise our model has predicted 1 on 7 various subsets(Combinations) from the root node.But mostly our leaf nodes has little observations, this shows how deep (OverFitting) our model has classified the dataset.
So now we need to Prune our model with cp value (threshold Value)
Now, let's see the complexity chart to set the threshold Value (cp)
```{r}
printcp(cart_tree)
plotcp(cart_tree)
```
  From the above plot it's clear that the X-Val Relative Error remains almost the same after the cp value of 0.010.
  so we use this cp value(0.010) as a threshold to prune the tree.
### Pruning
```{r}
pcart_tree <- prune(cart_tree,cp=0.010,"CP")
print(pcart_tree)
rpart.plot(pcart_tree)
```
   Now Our Pruned Tree has 1root node,5 branches(decision nodes) and 6 leaf nodes but still explains the dataset.
   However our root node remains the same(That our tree has predicted 0).
   Out of 6 leafs, here Our Pruned tree predicted that at three leafs our customer will accept the personal loan offered by thera bank.
   lets see the rules at each decision nodes to get the customers who can accept our personal Loan.
```{r}
path.rpart(pcart_tree,c(4,5,6,7))
```
If the Customer Falls either in the below mentioned three conditions, then there is a huge possibility of accepting the personal loan offered by our bank.
1. Income.(in.K/month)>=114.5
Education=2,3

2. Income.(in.K/month)>=114.5
Education=1
Family.members = 3,4

3. Income.(in.K/month)< 114.5
CCAvg>=2.95
C.D.Account = 1
Finally,let's use the decision tree to predict the class for each row and probability score on test dataset
Let's see how well the model perform in test and train dataset.
```{r}
train$Prediction <- predict(pcart_tree,data = train,type = "class")
train$Prob1 <- predict(pcart_tree,data = train,type = "prob")[,"1"]
head(train)
```
Similarily let's do this for test dataset
```{r}
test$Prediction <- predict(pcart_tree,test,type = "class")
test$Prob1 <- predict(pcart_tree,test,type = "prob")[,"1"]
head(test)
```
##Model Evaluation on both Test and Train dataset
### Confusion Matrix 
```{r}
library(caret)
set.seed(1234)
caret::confusionMatrix(train$Prediction,train$Personal.Loan,positive ="1")
```
Our cart Model performed well in train dataset with a accuracy of 98.5%
Our model has a sensitivity of 88.6% (True Positive Rate),i.e., how well our model predicted 1(customers who will accept the loan) in training dataset.
Our model has a sensitivity of 99.5% (True Negative Rate),i.e., how well our model predicted 0(customers who will not accept the loan) in training dataset.

###Building Rank Order Table for K-S,Gain,and Lift Chart on Training Dataset
Next lets calculate the decile thresholds and use those thresholds to compute various columns in a rank order table:
```{r}
probs=seq(0,1,length=11)
qs=quantile(train$Prob1, probs)
train$deciles=cut(train$Prob1, unique(qs),include.lowest = TRUE,right=FALSE)
table(train$deciles,train$Personal.Loan)
```
Now Let's construct a table with number of 1's and 0's and its prob deciles on Training Dataset.
```{r}
library(data.table)
trainDT = data.table(train)
rankTbl = trainDT[, list(
  cnt = length(Personal.Loan), 
  cnt_tar1 = sum(Personal.Loan == 1), 
  cnt_tar0 = sum(Personal.Loan == 0)
),by=deciles][order(-deciles)]
rankTbl$rrate = round(rankTbl$cnt_tar1 / rankTbl$cnt,4)*100;
rankTbl$cum_resp = cumsum(rankTbl$cnt_tar1)
rankTbl$cum_non_resp = cumsum(rankTbl$cnt_tar0)
rankTbl$cum_rel_resp = round(rankTbl$cum_resp / sum(rankTbl$cnt_tar1),4)*100;
rankTbl$cum_rel_non_resp = round(rankTbl$cum_non_resp / sum(rankTbl$cnt_tar0),4)*100;
rankTbl$ks = abs(rankTbl$cum_rel_resp - rankTbl$cum_rel_non_resp);
print(rankTbl)
```
According to KS - 91.22 if we target the top 10 decile group(0.146,1) there is high chance that the customer will respond to our loan offer.
We will next use the ROCR and ineq packages to compute AUC, KS and gini
```{r}
library(ROCR) # To Compute AUC
library(ineq)# To Compute the ks and gini scores
predObj = prediction(train$Prob1, train$Personal.Loan)
perf = performance(predObj, "tpr", "fpr") 
plot(perf,main="AUC Curve of CART MODEL ON TRAINING DATASET",,xlab="False Positive Rate",ylab="True Positive Rate")
KS = max(perf@y.values[[1]]-perf@x.values[[1]]) # The Maximum the Better 
print(KS)
auc = performance(predObj,"auc");
auc = as.numeric(auc@y.values)
print(auc)
gini = ineq(train$Prob1, type="Gini")
print(gini)
```
  Thumb Rule - Larger the auc and gini coefficient better the model is 
  We have a auc of 98% and gini coefficient of 87% which conveys the message that our model is a good model in training datset.
  Finally, we use the Concordance function in the InformationValue package to find the concordance and discordcance ratios:
```{r}
library(InformationValue)
print(Concordance(actuals=train$Personal.Loan, predictedScores=train$Prob1))# Concordance(actual,predicted score)
```
  Thumb Rule - Larger the Concordance Ratio better the model is 
  Here Concordance Ratio of 97% says that our model is a good model on training dataset.
  Now Let's Evaluate the model performance measure on testing dataset as well
  Now Lets check for the test dataset
```{r}
caret::confusionMatrix(test$Prediction,test$Personal.Loan,positive ="1")
```
Our cart Model also performed well in test dataset with a accuracy of 98.6%
Our model has a sensitivity of 91% (True Positive Rate),i.e., how well our model predicted 1(customers who will accept the loan) in training dataset.
Our model has a sensitivity of 99.5% (True Negative Rate),i.e., how well our model predicted 0(customers who will not accept the loan) in training dataset.
As per Confusion Matrix results our model has done a good job in both training and test dataset.

###Building Rank Order Table for K-S,Gain,and Lift Chart for Test Dataset
Next lets calculate the decile thresholds and use those thresholds to compute various columns in a rank order table:
```{r}
probs=seq(0,1,length=11)
qs1=quantile(test$Prob1, probs)
test$deciles=cut(test$Prob1, unique(qs1),include.lowest = TRUE,right=FALSE)
table(test$deciles,test$Personal.Loan)
```
Now Let's construct a table with number of 1's and 0's and its prob deciles in test dataset.
```{r}
testDT = data.table(test)
rankTbl = testDT[, list(
  cnt = length(Personal.Loan), 
  cnt_tar1 = sum(Personal.Loan == 1), 
  cnt_tar0 = sum(Personal.Loan == 0)
),by=deciles][order(-deciles)]
rankTbl$rrate = round(rankTbl$cnt_tar1 / rankTbl$cnt,4)*100;
rankTbl$cum_resp = cumsum(rankTbl$cnt_tar1)
rankTbl$cum_non_resp = cumsum(rankTbl$cnt_tar0)
rankTbl$cum_rel_resp = round(rankTbl$cum_resp / sum(rankTbl$cnt_tar1),4)*100;
rankTbl$cum_rel_non_resp = round(rankTbl$cum_non_resp / sum(rankTbl$cnt_tar0),4)*100;
rankTbl$ks = abs(rankTbl$cum_rel_resp - rankTbl$cum_rel_non_resp);
print(rankTbl)
```
According to KS - 92.53 if we target the top 10 decile group(0.103,1) there is high chance that the customer will respond to our loan offer.
###Computing AUC, KS and gini
```{r}
predObj1 = prediction(test$Prob1, test$Personal.Loan)
perf1 = performance(predObj1, "tpr", "fpr")
plot(perf1,main="AUC Curve of CART MODEL ON TESTING DATASET",xlab="False Positive Rate",ylab="True Positive Rate")
KS1 = max(perf1@y.values[[1]]-perf1@x.values[[1]]) # The Maximum the Better 
print(KS1)
auc1 = performance(predObj1,"auc");
auc1 = as.numeric(auc1@y.values)
print(auc1)
gini1 = ineq(test$Prob1, type="Gini")
print(gini1)
```
Thumb Rule - Larger the auc and gini coefficient better the model is.
We have a auc of 97% and gini coefficient of 88% which conveys the message that our model is a good model in training datset.
Finally, we use the Concordance function in the InformationValue package to find the concordance and discordcance ratios:
```{r}
print(Concordance(actuals=test$Personal.Loan, predictedScores=test$Prob1))# Concordance(actual,predicted score)
```
Thumb Rule - Larger the Concordance Ratio better the model is 
Here Concordance Ratio of 96% says that our model is a good model on testing dataset.

Let's build Random Forest model and check its performance
```{r}
library(randomForest)
set.seed(1235)
library(caTools)
splitrf <- sample.split(thera$Personal.Loan, SplitRatio = 0.7)
trainrf <- subset(thera,split== TRUE)
testrf <- subset(thera,split == FALSE)
```
Since Random Forest Function doesnot accept the column names with `()` we need to replace the column names so that we can build the model.
```{r}
trainrf$Ageinyears <- trainrf$`Age.(in.years)`
trainrf$Experienceinyears <- trainrf$`Experience.(in.years)`
trainrf$IncomeinKpermonth <- trainrf$`Income.(in.K/month)`
trainrf<- trainrf[,-c(1,2,3)]
# Similarily for test dataset
testrf$Ageinyears <- testrf$`Age.(in.years)`
testrf$Experienceinyears <- testrf$`Experience.(in.years)`
testrf$IncomeinKpermonth <- testrf$`Income.(in.K/month)`
testrf<- testrf[,-c(1,2,3)]
set.seed(1235)
RFModel <- randomForest(trainrf$Personal.Loan~.,data = trainrf,ntree = 501,mtry = 3,nodesize = 10,importance = TRUE)
print(RFModel)
```
# RF Model Error Rate
```{r}
print(RFModel$err.rate)
plot(RFModel, main="")
legend("topright", c("OOB", "0", "1"), text.col=1:5, lty=1:3, col=1:3)
title(main="Error Rates Random Forest TrainModel")
```
  From the RFModel error rate plot with respect to number of trees reveals that anything more than 251 trees, it doesn't add any value to the model instead it overfits the model.
Lets check the Important Variables
```{r}
print(RFModel$importance)
```
Larger the MeanDecrease values, the more important the corresponding variable.Here as per MeanDecrease(both accuracy anf Gini) Income in k/Month is more important Variable.
Now it's time to choose the right m-value to avoid overfitting for that we are going to tune our Random Forest Model.
```{r}
set.seed(1235)
TRFModel = tuneRF(x = trainrf[,-5], 
                 y=trainrf$Personal.Loan,
                 mtryStart = 3, 
                 ntreeTry = 251, 
                 stepFactor = 1.5, 
                 improve = 0.0001, 
                 trace=TRUE, 
                 plot = TRUE,
                 doBest = TRUE,
                 nodesize = 10, 
                 importance=TRUE
)
```
From the mtry vs OOBError plot we can see that at m-6 error is minimum so we can fix m value as 6.
```{r}
importance(TRFModel)
```
After tuning still the important variable didn't change,i.e.,Income in k/Month is the important variable
Now lets see how well our tuned random forest model predicts(perform) in our training and 
test dataset.
```{r}
trainrf$Prediction<- predict(TRFModel,data = trainrf,type = "class")
trainrf$Prob1<- predict(TRFModel,data = trainrf,type = "prob")[,"1"]
head(trainrf)
```
Similarily let's do this for test dataset
```{r}
testrf$Prediction <- predict(TRFModel,testrf,type = "class")
testrf$Prob1 <- predict(TRFModel,testrf,type = "prob")[,"1"]
head(testrf)
```
#Model Evaluation
## Confusion Matrix
```{r}
caret::confusionMatrix(trainrf$Prediction,trainrf$Personal.Loan,positive ="1")
```
Our RFModel performed well in train dataset with a accuracy of 98.6%
Our model has a sensitivity of 90.4% (True Positive Rate),i.e., how well our model predicted 1(customers who will accept the loan) in training dataset.
Our model has a sensitivity of 99.5% (True Negative Rate),i.e., how well our model predicted 0(customers who will not accept the loan) in training dataset.
###Building Rank Order Table for K-S,Gain,and Lift Chart for Random Forest model on Training Dataset
Next lets calculate the decile thresholds and use those thresholds to compute various columns in a rank order table:
```{r}
probs=seq(0,1,length=11)
qs2=quantile(trainrf$Prob1, probs)
trainrf$deciles=cut(trainrf$Prob1, unique(qs2),include.lowest = TRUE,right=FALSE)
table(trainrf$deciles,trainrf$Personal.Loan)
```
Now Let's construct a table with number of 1's and 0's and its prob deciles for random forest training dataset.
```{r}
trainDTRF = data.table(trainrf)
rankTbl = trainDTRF[, list(
  cnt = length(Personal.Loan), 
  cnt_tar1 = sum(Personal.Loan == 1), 
  cnt_tar0 = sum(Personal.Loan == 0)
),by=deciles][order(-deciles)]
rankTbl$rrate = round(rankTbl$cnt_tar1 / rankTbl$cnt,4)*100;
rankTbl$cum_resp = cumsum(rankTbl$cnt_tar1)
rankTbl$cum_non_resp = cumsum(rankTbl$cnt_tar0)
rankTbl$cum_rel_resp = round(rankTbl$cum_resp / sum(rankTbl$cnt_tar1),4)*100;
rankTbl$cum_rel_non_resp = round(rankTbl$cum_non_resp / sum(rankTbl$cnt_tar0),4)*100;
rankTbl$ks = abs(rankTbl$cum_rel_resp - rankTbl$cum_rel_non_resp);
print(rankTbl)
```
According to KS - 92.98 if we target the top 10 decile group(0.288,1) there is high chance that the customer will respond to our loan offer.
### Let's Compute AUC, KS and gini
```{r}
predObj2 = prediction(trainrf$Prob1, trainrf$Personal.Loan)
perf2 = performance(predObj2, "tpr", "fpr")
plot(perf2,main="AUC Curve of RF MODEL ON TRAINING DATASET",xlab="False Positive Rate",ylab="True Positive Rate")
KS2 = max(perf2@y.values[[1]]-perf2@x.values[[1]]) # The Maximum the Better 
print(KS2)
auc2 = performance(predObj2,"auc");
auc2 = as.numeric(auc2@y.values)
print(auc2)
gini2 = ineq(trainrf$Prob1, type="Gini")
print(gini2)
```
Thumb Rule - Larger the auc and gini coefficient better the model is 
We have a auc of 99% and gini coefficient of 89% which conveys the message that our model is a good model in training datset.
Finally, we use the Concordance function in the InformationValue package to find the concordance and discordcance ratios:
```{r}
print(Concordance(actuals=trainrf$Personal.Loan, predictedScores=trainrf$Prob1))# Concordance(actual,predicted score)
```
Thumb Rule - Larger the Concordance Ratio better the model is 
Here Concordance Ratio of 99.3% says that our RFmodel is a good model on training dataset.
Now Let's Evaluate the model performance measure on testing dataset as well
Now Lets check for the test dataset
```{r}
caret::confusionMatrix(testrf$Prediction,testrf$Personal.Loan,positive ="1")
```
Our RFModel also performed well in test dataset with a accuracy of 98.6%
Our model has a same sensitivity of 86.8% (True Positive Rate),i.e., how well our model predicted 1(customers who will accept the loan) in training dataset.
Our model has a sensitivity of 99.85% (True Negative Rate),i.e., how well our model predicted 0(customers who will not accept the loan) in training dataset.
As per Confusion Matrix results our model has done a good job in both training dataset than test dataset.
###Building Rank Order Table for K-S,Gain,and Lift Chart for RF Test Dataset
Next let's calculate the decile thresholds and use those thresholds to compute various columns in a rank order table:
```{r}
probs=seq(0,1,length=11)
qs3=quantile(testrf$Prob1, probs)
testrf$deciles=cut(testrf$Prob1, unique(qs3),include.lowest = TRUE,right=FALSE)
table(testrf$deciles,testrf$Personal.Loan)
```
Now Let's construct a table with number of 1's and 0's and its prob deciles in test dataset.
```{r}
testDTRF = data.table(testrf)
rankTbl = testDTRF[, list(
  cnt = length(Personal.Loan), 
  cnt_tar1 = sum(Personal.Loan == 1), 
  cnt_tar0 = sum(Personal.Loan == 0)
),by=deciles][order(-deciles)]
rankTbl$rrate = round(rankTbl$cnt_tar1 / rankTbl$cnt,4)*100;
rankTbl$cum_resp = cumsum(rankTbl$cnt_tar1)
rankTbl$cum_non_resp = cumsum(rankTbl$cnt_tar0)
rankTbl$cum_rel_resp = round(rankTbl$cum_resp / sum(rankTbl$cnt_tar1),4)*100;
rankTbl$cum_rel_non_resp = round(rankTbl$cum_non_resp / sum(rankTbl$cnt_tar0),4)*100;
rankTbl$ks = abs(rankTbl$cum_rel_resp - rankTbl$cum_rel_non_resp);
print(rankTbl)
```
According to KS - 92.64 if we target the top 10 decile group(0.217,1) there is high chance that the customer will respond to our loan offer.
# Computing AUC, KS and gini
```{r}
predObj3 = prediction(testrf$Prob1, testrf$Personal.Loan)
perf3 = performance(predObj3, "tpr", "fpr")
plot(perf3,main="AUC Curve of RF MODEL ON TESTING DATASET",xlab="False Positive Rate",ylab="True Positive Rate")
KS3 = max(perf3@y.values[[1]]-perf3@x.values[[1]]) # The Maximum the Better 
print(KS3)
auc3 = performance(predObj3,"auc");
auc3 = as.numeric(auc3@y.values)
print(auc3)
gini3 = ineq(testrf$Prob1, type="Gini")
print(gini3)
```
Thumb Rule - Larger the auc and gini coefficient better the model is 
We have a auc of 99.8% and gini coefficient of 88.9% which conveys the message that our model is a good model in training datset.
Finally, we use the Concordance function in the InformationValue package to find the concordance and discordcance ratios:
```{r}
print(Concordance(actuals=testrf$Personal.Loan, predictedScores=testrf$Prob1))# Concordance(actual,predicted score)
```
Thumb Rule - Larger the Concordance Ratio better the model is 
Here Concordance Ratio of 99.7% says that our model is a good model on testing dataset.
